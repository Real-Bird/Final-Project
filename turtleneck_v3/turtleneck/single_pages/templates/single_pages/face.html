<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Face Detection</title>
  </head>
  <body>
    <h1>Face Detection</h1>
    <button onclick="init();">start</button>
    <video id="video" autoplay style="display: none"></video>
    <canvas id="canvas" width="600px" height="400px"></canvas>
  </body>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
  <script>
      
      function init(){
        let video = document.getElementById("video");
        let model;
        // declare a canvas variable and get its context
        let canvas = document.getElementById("canvas");
        let ctx = canvas.getContext("2d");

        async function setupCamera(){
            navigator.mediaDevices
            .getUserMedia({
            video: { width: 600, height: 400 },
            audio: false,
            })
            .then((stream) => {
            video.srcObject = stream;
            });
        }


        async function detectFaces(){
            
            const prediction = await model.estimateFaces(video, false);
            console.log(prediction.length)
            // draw the video first
            ctx.drawImage(video, 0, 0, 600, 400);
            if (prediction.length == 1){
                
            prediction.forEach((pred) => {
            ctx.drawImage(video, 0, 0, 600, 400);
            ctx.beginPath();
            ctx.lineWidth = "4";
            ctx.strokeStyle = "blue";
            // the last two arguments are width and height
            // since blazeface returned only the coordinates, 
            // we can find the width and height by subtracting them.
            ctx.rect(
            pred.topLeft[0],
            pred.topLeft[1],
            pred.bottomRight[0] - pred.topLeft[0],
            pred.bottomRight[1] - pred.topLeft[1]
            );
            ctx.stroke();
            })

        } else {
            console.log('no face')
        }

        
        }

        setupCamera();
        
        video.addEventListener("loadeddata", async () => {
            model = await blazeface.load();
        // call detect faces every 100 milliseconds or 10 times every second
        setInterval(detectFaces, 100);
        clearInterval(detectFaces)
        });
    }
  </script>
</html>